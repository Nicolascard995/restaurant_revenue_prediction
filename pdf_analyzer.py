import openai
import json
import logging
import time
from typing import Dict, Any, List, Optional
import re
from pathlib import Path
import os
from datetime import datetime

# Importar el sistema de cach√©
from pdf_cache_manager import pdf_cache, PDFAnalysis

logger = logging.getLogger(__name__)

class PDFAnalyzer:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if self.api_key:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        self.model = "gpt-3.5-turbo"  # Versi√≥n m√°s econ√≥mica
        self.max_tokens = 1000  # Limitar tokens para econom√≠a
    
    def analyze_pdf_content(self, text_content: str, pdf_context: str = "") -> Dict[str, Any]:
        """Analiza el contenido del PDF usando ChatGPT econ√≥mico"""
        try:
            # Prompt optimizado para econom√≠a
            prompt = f"""
            Analiza este contenido de PDF relacionado con restaurantes y extrae informaci√≥n relevante:

            CONTENIDO: {text_content[:2000]}  # Limitar a 2000 caracteres

            Extrae y organiza la siguiente informaci√≥n en formato JSON:
            1. Datos demogr√°ficos (poblaci√≥n, ingresos, edad)
            2. Informaci√≥n de competencia (restaurantes cercanos, precios)
            3. Indicadores econ√≥micos (PIB, desempleo, inflaci√≥n)
            4. Eventos locales o estacionales
            5. Regulaciones o requisitos sanitarios
            6. Oportunidades de negocio identificadas
            7. Riesgos o amenazas detectadas

            Responde SOLO con JSON v√°lido, sin texto adicional.
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un analista experto en restaurantes. Extrae informaci√≥n relevante de PDFs y responde solo con JSON."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=0.3
            )
            
            # Parsear respuesta JSON
            try:
                analysis = json.loads(response.choices[0].message.content)
                return {
                    "success": True,
                    "analysis": analysis,
                    "tokens_used": response.usage.total_tokens
                }
            except json.JSONDecodeError:
                # Si no es JSON v√°lido, crear estructura b√°sica
                return {
                    "success": True,
                    "analysis": {
                        "datos_demograficos": {},
                        "competencia": {},
                        "indicadores_economicos": {},
                        "eventos_locales": [],
                        "regulaciones": [],
                        "oportunidades": [],
                        "riesgos": []
                    },
                    "raw_response": response.choices[0].message.content,
                    "tokens_used": response.usage.total_tokens
                }
                
        except Exception as e:
            logger.error(f"Error en an√°lisis de PDF: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": {}
            }
    
    def analyze_pdf_with_cache(self, file_path: str, file_id: str, filename: str) -> Dict[str, Any]:
        """Analiza PDF con sistema de cach√© inteligente"""
        start_time = time.time()
        
        try:
            # Verificar si ya existe an√°lisis en cach√©
            cached_analysis = pdf_cache.get_cached_analysis(file_path)
            if cached_analysis:
                logger.info(f"‚úÖ Usando an√°lisis en cach√© para {filename}")
                return {
                    "success": True,
                    "analysis": cached_analysis.analysis_data,
                    "tokens_used": cached_analysis.tokens_used,
                    "processing_time": cached_analysis.processing_time,
                    "from_cache": True,
                    "cache_hit": True
                }
            
            # Si no est√° en cach√©, analizar el PDF
            logger.info(f"üîÑ Analizando PDF nuevo: {filename}")
            
            # Extraer texto del PDF
            text_content = self._extract_text_from_file(file_path)
            if not text_content:
                raise Exception("No se pudo extraer texto del PDF")
            
            # Analizar contenido
            analysis_result = self.analyze_pdf_content(text_content)
            
            processing_time = time.time() - start_time
            
            if analysis_result["success"]:
                # Crear objeto de an√°lisis para cach√©
                analysis_obj = PDFAnalysis(
                    file_id=file_id,
                    filename=filename,
                    file_hash=pdf_cache._calculate_file_hash(file_path),
                    analysis_date=datetime.now().isoformat(),
                    analysis_data=analysis_result["analysis"],
                    tokens_used=analysis_result.get("tokens_used", 0),
                    processing_time=processing_time,
                    status="completed"
                )
                
                # Guardar en cach√©
                pdf_cache.save_analysis(analysis_obj)
                
                logger.info(f"‚úÖ An√°lisis completado y guardado en cach√©: {filename}")
                
                return {
                    "success": True,
                    "analysis": analysis_result["analysis"],
                    "tokens_used": analysis_result.get("tokens_used", 0),
                    "processing_time": processing_time,
                    "from_cache": False,
                    "cache_hit": False
                }
            else:
                # Guardar an√°lisis fallido en cach√©
                analysis_obj = PDFAnalysis(
                    file_id=file_id,
                    filename=filename,
                    file_hash=pdf_cache._calculate_file_hash(file_path),
                    analysis_date=datetime.now().isoformat(),
                    analysis_data={},
                    tokens_used=0,
                    processing_time=processing_time,
                    status="failed",
                    error_message=analysis_result.get("error", "Error desconocido")
                )
                
                pdf_cache.save_analysis(analysis_obj)
                
                return analysis_result
                
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"Error analizando PDF con cach√©: {e}")
            
            # Guardar error en cach√©
            analysis_obj = PDFAnalysis(
                file_id=file_id,
                filename=filename,
                file_hash=pdf_cache._calculate_file_hash(file_path),
                analysis_date=datetime.now().isoformat(),
                analysis_data={},
                tokens_used=0,
                processing_time=processing_time,
                status="failed",
                error_message=str(e)
            )
            
            pdf_cache.save_analysis(analysis_obj)
            
            return {
                "success": False,
                "error": str(e),
                "analysis": {},
                "processing_time": processing_time,
                "from_cache": False,
                "cache_hit": False
            }
    
    def _extract_text_from_file(self, file_path: str) -> str:
        """Extrae texto del archivo PDF"""
        try:
            import PyPDF2
            import pdfplumber
            
            text = ""
            
            # M√©todo 1: PyPDF2
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            # Si no hay texto, intentar con pdfplumber
            if not text.strip():
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
            
            return text.strip()
            
        except Exception as e:
            logger.error(f"Error extrayendo texto del PDF: {e}")
            return ""
    
    def extract_restaurant_data(self, text_content: str) -> Dict[str, Any]:
        """Extrae datos espec√≠ficos de restaurantes del PDF"""
        try:
            prompt = f"""
            Extrae datos espec√≠ficos de restaurantes de este texto:

            TEXTO: {text_content[:1500]}

            Busca y extrae:
            - Nombres de restaurantes
            - Direcciones y ubicaciones
            - Precios y costos
            - Horarios de operaci√≥n
            - Informaci√≥n de contacto
            - Rese√±as y calificaciones

            Responde en JSON con esta estructura:
            {{
                "restaurantes": [
                    {{
                        "nombre": "",
                        "direccion": "",
                        "precio_promedio": "",
                        "horarios": "",
                        "contacto": "",
                        "calificacion": ""
                    }}
                ]
            }}
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Extrae datos espec√≠ficos de restaurantes. Responde solo con JSON."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.2
            )
            
            try:
                data = json.loads(response.choices[0].message.content)
                return {
                    "success": True,
                    "data": data,
                    "tokens_used": response.usage.total_tokens
                }
            except json.JSONDecodeError:
                return {
                    "success": True,
                    "data": {"restaurantes": []},
                    "raw_response": response.choices[0].message.content,
                    "tokens_used": response.usage.total_tokens
                }
                
        except Exception as e:
            logger.error(f"Error al extraer datos de restaurantes: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": {"restaurantes": []}
            }
    
    def generate_insights(self, pdf_analysis: Dict[str, Any], restaurant_data: Dict[str, Any]) -> Dict[str, Any]:
        """Genera insights basados en el an√°lisis del PDF"""
        try:
            # Combinar an√°lisis y datos
            combined_data = {
                "analisis_pdf": pdf_analysis,
                "datos_restaurantes": restaurant_data
            }
            
            prompt = f"""
            Basado en este an√°lisis de PDF, genera insights para un restaurante:

            DATOS: {json.dumps(combined_data, ensure_ascii=False)[:1000]}

            Genera insights en estas categor√≠as:
            1. Oportunidades de mercado
            2. Amenazas competitivas
            3. Recomendaciones estrat√©gicas
            4. Factores de riesgo
            5. Ventajas competitivas

            Responde en JSON con esta estructura:
            {{
                "oportunidades": [],
                "amenazas": [],
                "recomendaciones": [],
                "riesgos": [],
                "ventajas": []
            }}
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Genera insights estrat√©gicos para restaurantes. Responde solo con JSON."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=600,
                temperature=0.4
            )
            
            try:
                insights = json.loads(response.choices[0].message.content)
                return {
                    "success": True,
                    "insights": insights,
                    "tokens_used": response.usage.total_tokens
                }
            except json.JSONDecodeError:
                return {
                    "success": True,
                    "insights": {
                        "oportunidades": [],
                        "amenazas": [],
                        "recomendaciones": [],
                        "riesgos": [],
                        "ventajas": []
                    },
                    "raw_response": response.choices[0].message.content,
                    "tokens_used": response.usage.total_tokens
                }
                
        except Exception as e:
            logger.error(f"Error al generar insights: {e}")
            return {
                "success": False,
                "error": str(e),
                "insights": {}
            }
    
    def get_cost_estimate(self, text_length: int) -> Dict[str, Any]:
        """Estima el costo del an√°lisis basado en la longitud del texto"""
        # Estimaci√≥n aproximada de tokens
        estimated_tokens = text_length * 1.5  # Factor de conversi√≥n
        estimated_cost = (estimated_tokens / 1000) * 0.002  # Costo por 1K tokens en gpt-3.5-turbo
        
        return {
            "estimated_tokens": int(estimated_tokens),
            "estimated_cost_usd": round(estimated_cost, 4),
            "model_used": self.model
        }

# Instancia global
pdf_analyzer = PDFAnalyzer() 